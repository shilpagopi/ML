# Tranformers
##### Advantages
* Capture long range dependencies using attention mechanism (which RNNs struggle with)
* Parallel processing

##### Core components
* Encoder: Processes the input sequence into a sequence of representations.   
* Decoder: Generates the output sequence based on the encoder's output.   
* Attention mechanism: Allows the model to focus on different parts of the input sequence when making predictions.   

  
